{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.sparse\n",
    "from scipy.spatial.distance import correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommendation System Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/dell/Desktop/Artificial Intelligence/Project/data_content.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing function\n",
    "def pre_process(text):\n",
    "    #lowercase \n",
    "    text = text.lower()\n",
    "    #remove commas,full stops etc\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    #remove stop words and lemmatize \n",
    "    words = nltk.word_tokenize(text)\n",
    "    #join the words\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the category and overview enteris\n",
    "df['new_overview'] = df['overview'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the pre-process function\n",
    "df['cleaned_text'] = df['new_overview'].apply(pre_process, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       chicago food planet gateway west loop spotligh...\n",
       "1       take san francisco two famous bridge minute bo...\n",
       "2       instead traditional tour bus vantigo transport...\n",
       "3       walked city street sailed bay water next step ...\n",
       "4       eat way one san francisco famous neighborhood ...\n",
       "                              ...                        \n",
       "1807    seeing washington landmark foot ambitious goal...\n",
       "1808    walk town one man show run semiretired former ...\n",
       "1809    u street tour run blue fern travel formerly ca...\n",
       "1810    adult older evening pub crawl take traveler ci...\n",
       "1811    blue orb savannah shadow tour based book name ...\n",
       "Name: cleaned_text, Length: 1812, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a corpus\n",
    "corpus = np.array(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert corpus to tfidf vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(corpus)\n",
    "vectors = tfidf.transform(corpus).toarray()\n",
    "#creating a dictionary of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(query,top = 10):\n",
    "    #pre process the query\n",
    "    query = pre_process(query)\n",
    "    #convert the query into tfidf vector\n",
    "    query_vector =tfidf.transform([query]).toarray()\n",
    "    #create a dictionary to keep track of scores\n",
    "    scores = {i:0 for i in range(len(vectors))}\n",
    "    for i,vector in enumerate(vectors):\n",
    "        scores[i] = np.dot(query_vector,vector) #cosine \n",
    "    #sort the dictionary according to the scores\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1],reverse = True)}\n",
    "    recs = []\n",
    "    for i in list(scores.keys())[0:top]:\n",
    "        recs.append(df.iloc[i]['itemId'])\n",
    "    return recs\n",
    "/Cosine Simlartiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: askfhvbk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input(\"Enter your query: \")\n",
    "recommendations(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Based Recommendation System Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/dell/Desktop/Artificial IntelligenceProject/data_collaborative.csv',encoding='cp1252')\n",
    "placeInfo=pd.read_csv('C:/Users/dell/Desktop/Artificial Intelligence/Project/data_content.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(data,placeInfo,left_on=\"itemId\",right_on=\"itemId\")\n",
    "userIds=data.userId\n",
    "userIds2=data[['userId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0:10,['userId']]\n",
    "data=pd.DataFrame.sort_values(data,['userId','itemId'],ascending=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def favoritePlace(activeUser,N):\n",
    "    topPlace=pd.DataFr.ame.sort_values(\n",
    "        data[data.userId==activeUser],['rating'],ascending=[0])[:N]\n",
    "    return list(topPlace.itemId)\n",
    "\n",
    "userItemRatingMatrix=pd.pivot_table(data, values='rating',index=['userId'], columns=['itemId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(user1,user2):\n",
    "    try:\n",
    "        user1=np.array(user1)-np.nanmean(user1)\n",
    "        user2=np.array(user2)-np.nanmean(user2)\n",
    "        commonItemIds=[i for i in range(len(user1)) if user1[i]>0 and user2[i]>0]\n",
    "        if len(commonItemIds)==0:\n",
    "           return 0\n",
    "        else:\n",
    "           user1=np.array([user1[i] for i in commonItemIds])\n",
    "           user2=np.array([user2[i] for i in commonItemIds])\n",
    "           return correlation(user1,user2)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You can't divide by zero!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestNeighbourRatings(activeUser,K):\n",
    "    try:\n",
    "        similarityMatrix=pd.DataFrame(index=userItemRatingMatrix.index,columns=['Similarity'])\n",
    "        for i in userItemRatingMatrix.index:\n",
    "            similarityMatrix.loc[i]=similarity(userItemRatingMatrix.loc[activeUser],userItemRatingMatrix.loc[i])\n",
    "        similarityMatrix=pd.DataFrame.sort_values(similarityMatrix,['Similarity'],ascending=[0])\n",
    "        nearestNeighbours=similarityMatrix[:K]\n",
    "        neighbourItemRatings=userItemRatingMatrix.loc[nearestNeighbours.index]\n",
    "        predictItemRating=pd.DataFrame(index=userItemRatingMatrix.columns, columns=['Rating'])\n",
    "        for i in userItemRatingMatrix.columns:\n",
    "            predictedRating=np.nanmean(userItemRatingMatrix.loc[activeUser])\n",
    "            for j in neighbourItemRatings.index:\n",
    "                if userItemRatingMatrix.loc[j,i]>0:\n",
    "                   predictedRating += (userItemRatingMatrix.loc[j,i]-np.nanmean(userItemRatingMatrix.loc[j]))*nearestNeighbours.loc[j,'Similarity']\n",
    "                predictItemRating.loc[i,'Rating']=predictedRating\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You can't divide by zero!\")            \n",
    "    return predictItemRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNRecommendations(activeUser,N):\n",
    "    try:\n",
    "        predictItemRating=nearestNeighbourRatings(activeUser,10)\n",
    "        placeAlreadyWatched=list(userItemRatingMatrix.loc[activeUser]\n",
    "                              .loc[userItemRatingMatrix.loc[activeUser]>0].index)\n",
    "        predictItemRating=predictItemRating.drop(placeAlreadyWatched)\n",
    "        topRecommendations=pd.DataFrame.sort_values(predictItemRating,\n",
    "                                                ['Rating'],ascending=[0])[:N]\n",
    "        topRecommendationTitles=(placeInfo.loc[placeInfo.itemId.isin(topRecommendations.index)])\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You can't divide by zero!\")\n",
    "    return list(topRecommendationTitles.itemId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter userid: 5\n",
      "The user's favorite places are: \n",
      "[9, 10, 20, 32, 31, 29, 5, 28, 12, 23]\n",
      "The recommended places for you are: \n",
      "[3, 6, 7, 11, 15, 17, 21, 22, 26, 30]\n"
     ]
    }
   ],
   "source": [
    "activeUser=int(input(\"Enter userid: \"))\n",
    "print(\"The user's favorite places are: \")\n",
    "print(favoritePlace(activeUser,10))\n",
    "\n",
    "print(\"The recommended places for you are: \")\n",
    "print(topNRecommendations(activeUser,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
